2020-12-08 16:42:26 Config:
{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8]],
 'all_joints_names': ['head',
                      'frleg',
                      'flleg',
                      'brleg',
                      'blleg',
                      'tailbase',
                      'midtail',
                      'upperbody',
                      'backbody'],
 'batch_size': 1,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_lion_finalDec8/lion_final_Leiter95shuffle1.mat',
 'dataset_type': 'imgaug',
 'deterministic': False,
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': '/Users/mikeleiter/opt/anaconda3/envs/DLC/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_lion_finalDec8/Documentation_data-lion_final_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 9,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': '/Users/mikeleiter/Documents/Project/lion_final-Leiter-2020-12-08',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': '/Users/mikeleiter/Documents/Project/lion_final-Leiter-2020-12-08/dlc-models/iteration-0/lion_finalDec8-trainset95shuffle1/train/snapshot',
 'stride': 8.0,
 'topheight': 400,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2020-12-08 16:42:42 iteration: 10 loss: 0.3541 lr: 0.005
2020-12-08 16:42:48 iteration: 20 loss: 0.0636 lr: 0.005
2020-12-08 16:42:55 iteration: 30 loss: 0.0520 lr: 0.005
2020-12-08 16:43:03 iteration: 40 loss: 0.0493 lr: 0.005
2020-12-08 16:43:11 iteration: 50 loss: 0.0478 lr: 0.005
2020-12-08 16:43:18 iteration: 60 loss: 0.0432 lr: 0.005
2020-12-08 16:43:26 iteration: 70 loss: 0.0433 lr: 0.005
2020-12-08 16:43:33 iteration: 80 loss: 0.0418 lr: 0.005
2020-12-08 16:43:41 iteration: 90 loss: 0.0424 lr: 0.005
2020-12-08 16:43:48 iteration: 100 loss: 0.0431 lr: 0.005
2020-12-08 16:43:56 iteration: 110 loss: 0.0410 lr: 0.005
2020-12-08 16:44:03 iteration: 120 loss: 0.0333 lr: 0.005
2020-12-08 16:44:10 iteration: 130 loss: 0.0382 lr: 0.005
2020-12-08 16:44:18 iteration: 140 loss: 0.0374 lr: 0.005
2020-12-08 16:44:23 iteration: 150 loss: 0.0309 lr: 0.005
2020-12-08 16:44:30 iteration: 160 loss: 0.0350 lr: 0.005
2020-12-08 16:44:36 iteration: 170 loss: 0.0317 lr: 0.005
2020-12-08 16:44:42 iteration: 180 loss: 0.0349 lr: 0.005
2020-12-08 16:44:47 iteration: 190 loss: 0.0308 lr: 0.005
2020-12-08 16:44:57 iteration: 200 loss: 0.0331 lr: 0.005
2020-12-08 16:45:04 iteration: 210 loss: 0.0325 lr: 0.005
2020-12-08 16:45:10 iteration: 220 loss: 0.0307 lr: 0.005
2020-12-08 16:45:16 iteration: 230 loss: 0.0288 lr: 0.005
2020-12-08 16:45:22 iteration: 240 loss: 0.0309 lr: 0.005
2020-12-08 16:45:30 iteration: 250 loss: 0.0347 lr: 0.005
2020-12-08 16:45:37 iteration: 260 loss: 0.0289 lr: 0.005
2020-12-08 16:45:44 iteration: 270 loss: 0.0288 lr: 0.005
2020-12-08 16:45:51 iteration: 280 loss: 0.0300 lr: 0.005
2020-12-08 16:46:00 iteration: 290 loss: 0.0266 lr: 0.005
2020-12-08 16:46:06 iteration: 300 loss: 0.0284 lr: 0.005
2020-12-08 16:46:14 iteration: 310 loss: 0.0263 lr: 0.005
2020-12-08 16:46:18 iteration: 320 loss: 0.0249 lr: 0.005
2020-12-08 16:46:26 iteration: 330 loss: 0.0250 lr: 0.005
2020-12-08 16:46:31 iteration: 340 loss: 0.0234 lr: 0.005
2020-12-08 16:46:39 iteration: 350 loss: 0.0275 lr: 0.005
2020-12-08 16:46:47 iteration: 360 loss: 0.0231 lr: 0.005
2020-12-08 16:46:54 iteration: 370 loss: 0.0240 lr: 0.005
2020-12-08 16:47:02 iteration: 380 loss: 0.0262 lr: 0.005
2020-12-08 16:47:09 iteration: 390 loss: 0.0263 lr: 0.005
2020-12-08 16:47:16 iteration: 400 loss: 0.0218 lr: 0.005
2020-12-08 16:47:24 iteration: 410 loss: 0.0240 lr: 0.005
2020-12-08 16:47:31 iteration: 420 loss: 0.0242 lr: 0.005
2020-12-08 16:47:37 iteration: 430 loss: 0.0243 lr: 0.005
2020-12-08 16:47:44 iteration: 440 loss: 0.0254 lr: 0.005
2020-12-08 16:47:51 iteration: 450 loss: 0.0255 lr: 0.005
2020-12-08 16:47:57 iteration: 460 loss: 0.0214 lr: 0.005
2020-12-08 16:48:05 iteration: 470 loss: 0.0208 lr: 0.005
2020-12-08 16:48:12 iteration: 480 loss: 0.0217 lr: 0.005
2020-12-08 16:48:19 iteration: 490 loss: 0.0198 lr: 0.005
2020-12-08 16:48:26 iteration: 500 loss: 0.0153 lr: 0.005
2020-12-08 16:48:35 iteration: 510 loss: 0.0208 lr: 0.005
2020-12-08 16:48:42 iteration: 520 loss: 0.0186 lr: 0.005
2020-12-08 16:48:47 iteration: 530 loss: 0.0196 lr: 0.005
2020-12-08 16:48:55 iteration: 540 loss: 0.0224 lr: 0.005
2020-12-08 16:49:02 iteration: 550 loss: 0.0195 lr: 0.005
2020-12-08 16:49:10 iteration: 560 loss: 0.0193 lr: 0.005
2020-12-08 16:49:15 iteration: 570 loss: 0.0205 lr: 0.005
2020-12-08 16:49:21 iteration: 580 loss: 0.0161 lr: 0.005
2020-12-08 16:49:27 iteration: 590 loss: 0.0187 lr: 0.005
2020-12-08 16:49:34 iteration: 600 loss: 0.0196 lr: 0.005
2020-12-08 16:49:41 iteration: 610 loss: 0.0181 lr: 0.005
2020-12-08 16:49:47 iteration: 620 loss: 0.0190 lr: 0.005
2020-12-08 16:49:56 iteration: 630 loss: 0.0162 lr: 0.005
2020-12-08 16:50:02 iteration: 640 loss: 0.0160 lr: 0.005
2020-12-08 16:50:09 iteration: 650 loss: 0.0181 lr: 0.005
2020-12-08 16:50:16 iteration: 660 loss: 0.0181 lr: 0.005
2020-12-08 16:50:21 iteration: 670 loss: 0.0170 lr: 0.005
2020-12-08 16:50:28 iteration: 680 loss: 0.0183 lr: 0.005
2020-12-08 16:50:36 iteration: 690 loss: 0.0182 lr: 0.005
2020-12-08 16:50:42 iteration: 700 loss: 0.0167 lr: 0.005
2020-12-08 16:50:50 iteration: 710 loss: 0.0140 lr: 0.005
2020-12-08 16:50:56 iteration: 720 loss: 0.0164 lr: 0.005
2020-12-08 16:51:04 iteration: 730 loss: 0.0154 lr: 0.005
2020-12-08 16:51:10 iteration: 740 loss: 0.0159 lr: 0.005
2020-12-08 16:51:17 iteration: 750 loss: 0.0174 lr: 0.005
2020-12-08 16:51:24 iteration: 760 loss: 0.0166 lr: 0.005
2020-12-08 16:51:31 iteration: 770 loss: 0.0157 lr: 0.005
2020-12-08 16:51:38 iteration: 780 loss: 0.0194 lr: 0.005
2020-12-08 16:51:45 iteration: 790 loss: 0.0194 lr: 0.005
2020-12-08 16:51:53 iteration: 800 loss: 0.0165 lr: 0.005
2020-12-08 16:52:00 iteration: 810 loss: 0.0182 lr: 0.005
2020-12-08 16:52:07 iteration: 820 loss: 0.0147 lr: 0.005
2020-12-08 16:52:14 iteration: 830 loss: 0.0127 lr: 0.005
2020-12-08 16:52:21 iteration: 840 loss: 0.0163 lr: 0.005
2020-12-08 16:52:27 iteration: 850 loss: 0.0158 lr: 0.005
2020-12-08 16:52:34 iteration: 860 loss: 0.0134 lr: 0.005
2020-12-08 17:04:35 iteration: 870 loss: 0.0158 lr: 0.005
2020-12-08 17:04:42 iteration: 880 loss: 0.0135 lr: 0.005
2020-12-08 17:04:49 iteration: 890 loss: 0.0139 lr: 0.005
2020-12-08 17:04:58 iteration: 900 loss: 0.0133 lr: 0.005
2020-12-08 17:05:05 iteration: 910 loss: 0.0123 lr: 0.005
2020-12-08 17:05:11 iteration: 920 loss: 0.0145 lr: 0.005
2020-12-08 17:05:18 iteration: 930 loss: 0.0117 lr: 0.005
2020-12-08 17:05:23 iteration: 940 loss: 0.0160 lr: 0.005
2020-12-08 17:05:31 iteration: 950 loss: 0.0133 lr: 0.005
2020-12-08 17:05:38 iteration: 960 loss: 0.0151 lr: 0.005
2020-12-08 17:05:44 iteration: 970 loss: 0.0127 lr: 0.005
2020-12-08 17:05:48 iteration: 980 loss: 0.0134 lr: 0.005
2020-12-08 17:05:55 iteration: 990 loss: 0.0126 lr: 0.005
2020-12-08 17:06:03 iteration: 1000 loss: 0.0133 lr: 0.005
2020-12-08 17:06:12 iteration: 1010 loss: 0.0126 lr: 0.005
2020-12-08 17:06:19 iteration: 1020 loss: 0.0134 lr: 0.005
2020-12-08 17:06:27 iteration: 1030 loss: 0.0135 lr: 0.005
2020-12-08 17:06:33 iteration: 1040 loss: 0.0115 lr: 0.005
2020-12-08 17:06:41 iteration: 1050 loss: 0.0127 lr: 0.005
2020-12-08 17:06:47 iteration: 1060 loss: 0.0132 lr: 0.005
2020-12-08 17:06:53 iteration: 1070 loss: 0.0128 lr: 0.005
2020-12-08 17:07:01 iteration: 1080 loss: 0.0130 lr: 0.005
2020-12-08 17:07:07 iteration: 1090 loss: 0.0110 lr: 0.005
2020-12-08 17:09:28 iteration: 1100 loss: 0.0122 lr: 0.005
